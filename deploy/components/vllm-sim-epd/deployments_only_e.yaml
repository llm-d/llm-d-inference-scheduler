---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-sim-e
  labels:
    app: ${POOL_NAME}
spec:
  replicas: ${VLLM_REPLICA_COUNT_E}
  selector:
    matchLabels:
      app: ${POOL_NAME}
  template:
    metadata:
      labels:
        app: ${POOL_NAME}
        llm-d.ai/role: encode
    spec:
      volumes:
        - name: data
          hostPath:
            path: /mnt/wsl/hf-models
            type: DirectoryOrCreate
        - name: shm
          emptyDir:
            medium: Memory
      containers:
        - name: vllm
          resources:
            requests:
              memory: "4Gi"
            limits:
              memory: "8Gi"
          image: ghcr.io/revit13/vllm-cpu-env:latest
          command: ["python3", "-m", "vllm.entrypoints.openai.api_server"]
          imagePullPolicy: "IfNotPresent"
          args:
            - "--port=8000"
            - "--model=Qwen/Qwen2.5-1.5B-Instruct"
            - "--max-num-seqs=1"
            - "--gpu-memory-utilization=0.7"
            - "--max-model-len=4096"
          ports:
            - name: encode-http
              containerPort: 8000
              protocol: TCP
            - name: encode-rank1
              containerPort: 8001
              protocol: TCP
            - name: encode-rank2
              containerPort: 8002
              protocol: TCP
            - name: encode-rank3
              containerPort: 8003
              protocol: TCP
            - name: encode-rank4
              containerPort: 8004
              protocol: TCP
            - name: encode-rank5
              containerPort: 8005
              protocol: TCP
            - name: encode-rank6
              containerPort: 8006
              protocol: TCP
            - name: encode-rank7
              containerPort: 8007
              protocol: TCP
          env:
            - name: PORT
              value: "8000"
            - name: HUGGINGFACE_HUB_CACHE
              value: "/data"
            - name: VLLM_CPU_KVCACHE_SPACE  # <--- ADD THIS
              value: "1"
          volumeMounts:
            - mountPath: /data
              name: data
            - mountPath: /dev/shm
              name: shm
