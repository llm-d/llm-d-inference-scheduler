# ------------------------------------------------------------------------------
# Inference Gateway
#
# This provides a working stack for an inference Gateway, including the Gateway
# itself, the Endpoint Picker (EPP) attached to it, and the Inference Pools and
# Inference Models to collect pods from a model serving framework (e.g. VLLM,
# or even just the VLLM Simulator).
#
# ------------------------------------------------------------------------------
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- service-accounts.yaml
- rbac.yaml
- inference-pools.yaml
- inference-models.yaml
- services.yaml
- deployments.yaml
- gateways.yaml
- httproutes.yaml

images:
- name: quay.io/llm-d/gateway-api-inference-extension/epp
  newTag: 0.0.1
